{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import h5py\n",
    "import os\n",
    "\n",
    "from inference import *\n",
    "from modules import *\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a Model object to load the pretrained model\n",
    "folderpath_clf = \"/home/samet/et-estimation/src/checkpoint/2023-09-26_09-24-10/\"\n",
    "model = Model(folderpath_clf=folderpath_clf, clf_idx=49)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2021\n",
    "batch_size = 1\n",
    "split = \"test\"\n",
    "\n",
    "# Initialize dataset\n",
    "dset = model.init_dset(year, split)\n",
    "# Initialize iterator\n",
    "iterator = model.init_iterator(dset)\n",
    "\n",
    "iterator = DataLoader(\n",
    "    dset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=False,\n",
    "    pin_memory=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.clf.eval()  # Set the model to evaluation mode\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    }
   ],
   "source": [
    "n_example = 200\n",
    "ct = 1\n",
    "# Iterate over the iterator\n",
    "for (\n",
    "    s1,\n",
    "    s2,\n",
    "    et,\n",
    "    weather,\n",
    "    dem,\n",
    "    sm,\n",
    "    soilgrids,\n",
    "    cropland_mask,\n",
    ") in iterator:\n",
    "    # Carry tensors to the specified device (cpu or gpu)\n",
    "    (\n",
    "        s1,\n",
    "        s2,\n",
    "        et,\n",
    "        weather,\n",
    "        dem,\n",
    "        sm,\n",
    "        soilgrids,\n",
    "        cropland_mask,\n",
    "    ) = model._to_device(\n",
    "        s1,\n",
    "        s2,\n",
    "        et,\n",
    "        weather,\n",
    "        dem,\n",
    "        sm,\n",
    "        soilgrids,\n",
    "        cropland_mask,\n",
    "    )\n",
    "\n",
    "    R = torch.sum(cropland_mask).item() / (128**2)\n",
    "    if R < 0.7:\n",
    "        continue\n",
    "\n",
    "    with torch.cuda.amp.autocast():\n",
    "        y_ = model._predict_step(\n",
    "            s1,\n",
    "            s2,\n",
    "            weather,\n",
    "            dem,\n",
    "            sm,\n",
    "            soilgrids,\n",
    "        ).float()\n",
    "        \n",
    "        target_folderpath_s1_tensor = \"/home/samet/for-inference/data/tensors/s1\"\n",
    "        target_folderpath_era5_tensor = \"/home/samet/for-inference/data/tensors/era5\"\n",
    "        target_folderpath_dem_tensor = \"/home/samet/for-inference/data/tensors/dem\"\n",
    "        target_folderpath_et_gt_tensor = \"/home/samet/for-inference/data/tensors/et-gt\"\n",
    "        target_folderpath_et_pred_tensor = \"/home/samet/for-inference/data/tensors/et-pred\"\n",
    "        target_folderpath_cropland_mask_tensor = \"/home/samet/for-inference/data/tensors/cropland-mask\"\n",
    "\n",
    "        os.makedirs(target_folderpath_s1_tensor, exist_ok=True)\n",
    "        os.makedirs(target_folderpath_era5_tensor, exist_ok=True)\n",
    "        os.makedirs(target_folderpath_dem_tensor, exist_ok=True)\n",
    "        os.makedirs(target_folderpath_et_gt_tensor, exist_ok=True)\n",
    "        os.makedirs(target_folderpath_et_pred_tensor, exist_ok=True)\n",
    "        os.makedirs(target_folderpath_cropland_mask_tensor, exist_ok=True)\n",
    "\n",
    "        torch.save(s1, f\"{target_folderpath_s1_tensor}/s1_{ct:04}.pt\")\n",
    "        torch.save(weather, f\"{target_folderpath_era5_tensor}/era5_{ct:04}.pt\")\n",
    "        torch.save(dem, f\"{target_folderpath_dem_tensor}/dem_{ct:04}.pt\")\n",
    "        torch.save(et, f\"{target_folderpath_et_gt_tensor}/et_gt_{ct:04}.pt\")\n",
    "        torch.save(y_, f\"{target_folderpath_et_pred_tensor}/et_pred_{ct:04}.pt\")\n",
    "        torch.save(cropland_mask, f\"{target_folderpath_cropland_mask_tensor}/cropland_mask_{ct:04}.pt\")  \n",
    "\n",
    "    # Convert torch.tensor to numpy.array\n",
    "    s2_img = s2.cpu().numpy().transpose(0, 2, 3, 1).squeeze()[:,:,2::-1]\n",
    "    y_pred = y_.cpu().numpy().transpose(0, 2, 3, 1).squeeze()\n",
    "    et_img = et.cpu().numpy().transpose(0, 2, 3, 1).squeeze()\n",
    "    cropland_mask_img = cropland_mask.cpu().numpy().squeeze()\n",
    "\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "    axes[0].imshow(s2_img)\n",
    "    axes[1].imshow(et_img, cmap='coolwarm', vmin=0, vmax=10)\n",
    "    axes[2].imshow(y_pred, cmap='coolwarm', vmin=0, vmax=10)\n",
    "    axes[3].imshow(cropland_mask_img, cmap='RdYlGn', vmin=0, vmax=1, interpolation='none')\n",
    "    #plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    target_folderpath_rgb = \"/home/samet/for-inference/data/figs/rgb\"\n",
    "    target_folderpath_et_gt = \"/home/samet/for-inference/data/figs/et-gt\"\n",
    "    target_folderpath_et_pred = \"/home/samet/for-inference/data/figs/et-pred\"\n",
    "    target_folderpath_cropland_mask = \"/home/samet/for-inference/data/figs/cropland-mask\"\n",
    "\n",
    "    os.makedirs(target_folderpath_rgb, exist_ok=True)\n",
    "    os.makedirs(target_folderpath_et_gt, exist_ok=True)\n",
    "    os.makedirs(target_folderpath_et_pred, exist_ok=True)\n",
    "    os.makedirs(target_folderpath_cropland_mask, exist_ok=True)\n",
    "\n",
    "    plt.imshow(s2_img)\n",
    "    plt.axis('off')\n",
    "    plt.savefig(f\"{target_folderpath_rgb}/rgb_{ct:04}.png\", bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    plt.imshow(et_img, cmap='coolwarm', vmin=0, vmax=8)\n",
    "    plt.axis('off')\n",
    "    plt.savefig(f\"{target_folderpath_et_gt}/et_gt_{ct:04}.png\", bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    plt.imshow(y_pred, cmap='coolwarm', vmin=0, vmax=8)\n",
    "    plt.axis('off')\n",
    "    plt.savefig(f\"{target_folderpath_et_pred}/et_pred_{ct:04}.png\", bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    plt.imshow(cropland_mask_img, cmap='RdYlGn', vmin=0, vmax=1, interpolation='none')\n",
    "    plt.axis('off')\n",
    "    plt.savefig(f\"{target_folderpath_cropland_mask}/cropland_mask_{ct:04}.png\", bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    if ct >= n_example:\n",
    "        break\n",
    "    ct += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "et-estimation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
